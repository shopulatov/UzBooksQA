{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b53d4bf5-bc95-4fbf-bab1-78807568d0af",
   "metadata": {},
   "source": [
    "# Setup and Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc8ffe5b-16b5-4143-a086-59e59283ee43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using transformers v4.25.1\n",
      "Using datasets v2.11.0\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "\n",
    "setup_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fc10fbc-2b2a-468a-9eec-739302dcddc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get install -qq git-lfs\n",
    "\n",
    "import os\n",
    "os.environ['TOKENIZERS_PARALLELISM']='false'\n",
    "\n",
    "import warnings, logging\n",
    "warnings.simplefilter('ignore')\n",
    "logging.disable(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a919d5-a5ba-4f56-a080-fe05cd62afb3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Haystack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5814d05d-f97f-40cb-b39f-bb0e97930096",
   "metadata": {},
   "source": [
    "## Initializing Haystack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72619788-0c58-4e54-9bcc-0f84de226c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('elasticsearch-7.9.2'):\n",
    "    ! wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.9.2-linux-x86_64.tar.gz -q\n",
    "    ! tar -xzf elasticsearch-7.9.2-linux-x86_64.tar.gz\n",
    "    ! chown -R daemon:daemon elasticsearch-7.9.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53fbb3b7-7608-4487-87df-9a0fffc16e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash --bg\n",
    "\n",
    "sudo -u daemon -- elasticsearch-7.9.2/bin/elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5115d29d-de4a-464b-8d34-9bb7dcda7653",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf93e755-d024-4aae-8962-78efe326f2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\" : \"nsh6lp2hal\",\n",
      "  \"cluster_name\" : \"elasticsearch\",\n",
      "  \"cluster_uuid\" : \"84RYn7Q3Rr-3lyKlq_dCdw\",\n",
      "  \"version\" : {\n",
      "    \"number\" : \"7.9.2\",\n",
      "    \"build_flavor\" : \"default\",\n",
      "    \"build_type\" : \"tar\",\n",
      "    \"build_hash\" : \"d34da0ea4a966c4e49417f2da2f244e3e97b4e6e\",\n",
      "    \"build_date\" : \"2020-09-23T00:45:33.626720Z\",\n",
      "    \"build_snapshot\" : false,\n",
      "    \"lucene_version\" : \"8.6.2\",\n",
      "    \"minimum_wire_compatibility_version\" : \"6.8.0\",\n",
      "    \"minimum_index_compatibility_version\" : \"6.0.0-beta1\"\n",
      "  },\n",
      "  \"tagline\" : \"You Know, for Search\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!curl -X GET \"localhost:9200/?pretty\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68c02bfc-0c92-41a4-819e-5256b147792f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.document_stores import ElasticsearchDocumentStore\n",
    "\n",
    "host=os.environ.get(\"ELASTICSEARCH_HOST\", \"localhost\")\n",
    "document_store=ElasticsearchDocumentStore(\n",
    "    host=host,\n",
    "    port=9200,\n",
    "    username=\"\",\n",
    "    password=\"\",\n",
    "    index='documents'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ea7e22-ba01-4b64-9f7a-9821adf86416",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('data/books.csv')\n",
    "\n",
    "docs=[{\"content\":row['description'],\n",
    "       \"meta\":{'title':row['title']}}\n",
    "      for _,row in df.drop_duplicates(subset='title')\n",
    "      .iterrows()]\n",
    "\n",
    "document_store.write_documents(docs, index='documents')\n",
    "print(f\"Loaded {document_store.get_document_count()} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3e4b07c-ef2f-4aee-86b9-01883f6a178a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 2981 documents i document store.\n"
     ]
    }
   ],
   "source": [
    "print(f\"We have {document_store.get_document_count()} documents i document store.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dae06b4c-5a74-4d0c-a2f7-6e9cc2992c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.nodes import BM25Retriever\n",
    "\n",
    "bm25_retriever=BM25Retriever(document_store=document_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "836dd335-2680-4d30-9438-a9812ac43934",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.nodes import FARMReader\n",
    "\n",
    "model_ckpt='timpal0l/mdeberta-v3-base-squad2'\n",
    "max_seq_length, doc_stride=384, 128\n",
    "\n",
    "reader=FARMReader(model_name_or_path=model_ckpt,\n",
    "                  progress_bar=False,\n",
    "                  max_seq_len=max_seq_length,\n",
    "                  doc_stride=doc_stride,\n",
    "                  return_no_answer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d3076d-531b-48b4-a692-e96f5059b606",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename='train.json'\n",
    "dev_filename='dev.json'\n",
    "\n",
    "reader.train(data_dir='data/', use_gpu=True, n_epochs=3, batch_size=16,\n",
    "             train_filename=train_filename, dev_filename=dev_filename)\n",
    "reader.save('mdeberta-model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d636c1-e06e-4917-9eba-d6c9bf206bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader=FARMReader(model_name_or_path='mdeberta-model',\n",
    "                  progress_bar=False,\n",
    "                  max_seq_len=max_seq_length,\n",
    "                  doc_stride=doc_stride,\n",
    "                  return_no_answer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "268036ab-36b9-4241-9d6c-1bb160bf65f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.pipelines import ExtractiveQAPipeline\n",
    "\n",
    "pipe=ExtractiveQAPipeline(reader, bm25_retriever)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "439dfc3f-d9e9-4175-b312-f96d669e186b",
   "metadata": {},
   "source": [
    "import gradio as gr\n",
    "\n",
    "title = \"Extractive QA with AsaxiyBooks\"\n",
    "description = \"\"\"\n",
    "<p style=\"text-align: justify;\"> \n",
    "Asaxiy Books, the largest online book seller in Uzbekistan, has been lacking an innovative QA model for its users to interact with. Their current method of answering user questions mostly revolves around providing information on prices and delivery times. To solve this issue, we have developed an Open Domain QA model with a focus on providing information about books. While our model is not yet perfect, it represents a significant step forward in enhancing the user experience and facilitating access to information about books.\n",
    "</p>\n",
    "\"\"\"\n",
    "\n",
    "article = \"\"\"\n",
    "<p style=\"text-align: justify;\">\n",
    "    <h3>Challenges in Open Domain QA for Asaxiy Books</h3>\n",
    "    <ul>\n",
    "        <li>Asaxiy Books, the largest online book seller in Uzbekistan, has limited support for customer queries and relies mostly on human assistance for answering questions related to books. This approach can be inefficient and may not always provide satisfactory results to customers.\n",
    "        <li>In order to improve the user experience and to provide better support, we propose an Open Domain Question Answering (QA) system for Asaxiy Books that can help customers find information about books and answer their queries in a more efficient manner.\n",
    "        <li>The QA system is built using Elasticsearch as the database and Haystack as the framework for running the pipeline.\n",
    "    </ul>\n",
    "    <h3>Implementation Details</h3>\n",
    "    <ul>\n",
    "        <li>We have used pre-trained models from the Hugging Face Transformers library, specifically the SQuAD 2.0 model in order to perform extractive QA. These models have been trained on large datasets of text and can accurately extract answers to questions from text.\n",
    "        <li>The Haystack framework has been used to integrate Elasticsearch with the QA system. Elasticsearch provides fast and efficient indexing and querying of large volumes of text data, making it an ideal choice for the backend of the QA system.\n",
    "        <li>The QA system consists of a retriever and a reader. The retriever performs an initial search of the Elasticsearch index to identify the most relevant documents to a given question. The reader then extracts the answer from these documents using the pre-trained models.\n",
    "        <li>The QA system has been integrated into a web interface, allowing customers to easily interact with the system and obtain answers to their queries.\n",
    "    </ul>\n",
    "    <h3>Conclusion and Future Work</h3>\n",
    "    <ul>\n",
    "        <li>The Open Domain QA system developed for Asaxiy Books provides an efficient and accurate method for answering customer queries related to books. This system has the potential to greatly improve the user experience and reduce the workload of customer service representatives.\n",
    "        <li>Future work on this system could involve improving the accuracy of the models used for QA, as well as incorporating additional features such as question generation and summarization.\n",
    "    </ul>\n",
    "</p>\n",
    "\n",
    "</p>\n",
    "<h3>Authors</h3>\n",
    "<a href=\"https://www.linkedin.com/in/abrorshopulatov/\">Abror Shopulatov</a>\n",
    "<a href=\"https://www.linkedin.com/in/navfalbek/\">Navfalbek Makhfuzullaev</a>\n",
    "<a href=\"https://www.linkedin.com/in/samir-irgashev-47522717a/\">Samir Irgashev</a>\n",
    "\"\"\"\n",
    "\n",
    "examples = [\n",
    "    [\"Dasturlash ni qaysi kitobdan boshlab o'rgansam bo'ladi?\"],\n",
    "    [\"Ahmedov va Nizamutdinovalarning Anatomiya kitobi kimlar uchun mo'ljallangan?\"]\n",
    "]\n",
    "\n",
    "def qa_model(question):\n",
    "    preds=pipe.run(query=question, params={'Retriever':{'top_k':3},\n",
    "                                           'Reader':{'top_k':3}})\n",
    "    return preds['answers'][0].answer, preds['answers'][0].context\n",
    "\n",
    "face = gr.Interface(\n",
    "    fn=qa_model, \n",
    "    inputs=[            \n",
    "        gr.inputs.Textbox(lines=3, placeholder=\"Question Hereâ€¦ \")\n",
    "    ], \n",
    "    outputs=[\n",
    "        gr.outputs.Textbox(label=\"Answer\"),\n",
    "        gr.outputs.Textbox(label=\"Context\"),\n",
    "    ],\n",
    "    layout=\"vertical\",\n",
    "    title=title,\n",
    "    examples=examples,\n",
    "    description=description,\n",
    "    article=article,\n",
    "    allow_flagging =\"never\"\n",
    ")\n",
    "face.launch(share=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eb95deaa-602c-4011-86ed-e59a9ffb01c1",
   "metadata": {},
   "source": [
    "face.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a139c1bd-addc-4123-ab9e-4851e7aec60c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
